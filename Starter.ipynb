{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3e52cc-8956-413b-9d1f-eda1a003f835",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'custom_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtemporalio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtemporalio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontrib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pydantic_data_converter\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcustom_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     BertEvalRequest,\n\u001b[32m     22\u001b[39m     BertFineTuneConfig,\n\u001b[32m     23\u001b[39m     CoordinatorWorkflowConfig,\n\u001b[32m     24\u001b[39m     SweepRequest,\n\u001b[32m     25\u001b[39m     SweepSpace,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mworkflows\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     LadderSweepWorkflow,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------------\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Sample Sweep Configurations\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------------\u001b[39;00m\n\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Sample 1: {Model: BERT Uncased - Dataset: Glue}\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'custom_types'"
     ]
    }
   ],
   "source": [
    "\"\"\"CLI entrypoint for running BERT hyperparameter sweeps with Temporal.\n",
    "\n",
    "This script is intentionally small and tutorial-friendly:\n",
    "\n",
    "- It defines a handful of sample :class:`CoordinatorWorkflowConfig` objects for\n",
    "  different model/dataset combinations.\n",
    "- It builds a :class:`SweepRequest` for the ladder-style\n",
    "  :class:`LadderSweepWorkflow`.\n",
    "- It connects to a local Temporal server, executes the workflow, and prints a\n",
    "  compact summary of the best runs.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "from temporalio.client import Client\n",
    "from temporalio.contrib.pydantic import pydantic_data_converter\n",
    "\n",
    "from custom_types import (\n",
    "    BertEvalRequest,\n",
    "    BertFineTuneConfig,\n",
    "    CoordinatorWorkflowConfig,\n",
    "    SweepRequest,\n",
    "    SweepSpace,\n",
    ")\n",
    "from workflows import (\n",
    "    LadderSweepWorkflow,\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Sample Sweep Configurations\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Sample 1: {Model: BERT Uncased - Dataset: Glue}\n",
    "config_1 = CoordinatorWorkflowConfig(\n",
    "    fine_tune_config=BertFineTuneConfig(\n",
    "        model_name=\"bert-base-uncased\",\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=\"sst2\",\n",
    "        num_epochs=2,\n",
    "        batch_size=8,\n",
    "        learning_rate=2e-5,\n",
    "        max_seq_length=128,\n",
    "        use_gpu=True,\n",
    "        max_train_samples=3_000,\n",
    "        max_eval_samples=2_000,\n",
    "        seed=random.randint(0, 10000),\n",
    "    ),\n",
    "    evaluation_config=BertEvalRequest(\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=\"sst2\",\n",
    "        split=\"validation\",\n",
    "        max_eval_samples=1_000,\n",
    "        max_seq_length=128,\n",
    "        batch_size=32,\n",
    "        use_gpu=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Sample 2 {Model: BERT Cased - Dataset: Glue}\n",
    "config_2 = CoordinatorWorkflowConfig(\n",
    "    fine_tune_config=BertFineTuneConfig(\n",
    "        model_name=\"bert-base-cased\",\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=\"sst2\",\n",
    "        num_epochs=10,\n",
    "        batch_size=16,\n",
    "        learning_rate=3e-5,\n",
    "        max_seq_length=128,\n",
    "        use_gpu=True,\n",
    "        max_train_samples=3_000,\n",
    "        max_eval_samples=2_000,\n",
    "        seed=random.randint(0, 10000),\n",
    "    ),\n",
    "    evaluation_config=BertEvalRequest(\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=\"sst2\",\n",
    "        split=\"validation\",\n",
    "        max_eval_samples=1_000,\n",
    "        max_seq_length=128,\n",
    "        batch_size=32,\n",
    "        use_gpu=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Sample 3 {Model: BERT Uncased - Dataset: IMDB}\n",
    "seed = random.randint(0, 10000)\n",
    "config_3 = CoordinatorWorkflowConfig(\n",
    "    fine_tune_config=BertFineTuneConfig(\n",
    "        model_name=\"bert-base-uncased\",\n",
    "        dataset_name=\"imdb\",\n",
    "        dataset_config_name=\"plain_text\",\n",
    "        num_epochs=10,\n",
    "        batch_size=32,\n",
    "        learning_rate=2e-5,\n",
    "        max_seq_length=256,\n",
    "        use_gpu=True,\n",
    "        max_train_samples=5_000,\n",
    "        max_eval_samples=2_000,\n",
    "        seed=seed,\n",
    "    ),\n",
    "    evaluation_config=BertEvalRequest(\n",
    "        dataset_name=\"imdb\",\n",
    "        dataset_config_name=\"plain_text\",\n",
    "        split=\"test\",\n",
    "        max_eval_samples=1_000,\n",
    "        max_seq_length=256,\n",
    "        batch_size=32,\n",
    "        use_gpu=True,\n",
    "        seed=seed,\n",
    "    ),\n",
    ")\n",
    "# Sample 4: {Model: DistilBERT - Dataset: Glue}\n",
    "seed = random.randint(0, 10000)\n",
    "config_4 = CoordinatorWorkflowConfig(\n",
    "    fine_tune_config=BertFineTuneConfig(\n",
    "        model_name=\"distilbert-base-uncased\",\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=\"sst2\",\n",
    "        num_epochs=2,\n",
    "        batch_size=4,  # MPS-safe\n",
    "        learning_rate=5e-5,\n",
    "        max_seq_length=64,  # MPS-safe\n",
    "        use_gpu=True,\n",
    "        max_train_samples=2_000,\n",
    "        max_eval_samples=1_000,\n",
    "        shuffle_before_select=True,\n",
    "        seed=seed,\n",
    "        # optional overrides if you added them:\n",
    "        # text_field=None,\n",
    "        # text_pair_field=None,\n",
    "        # label_field=None,\n",
    "        # task_type=\"auto\",\n",
    "    ),\n",
    "    evaluation_config=BertEvalRequest(\n",
    "        # run_id will be filled in by the coordinator after training\n",
    "        run_id=None,\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=\"sst2\",\n",
    "        split=\"validation\",\n",
    "        max_eval_samples=1_000,\n",
    "        max_seq_length=64,\n",
    "        batch_size=32,\n",
    "        use_gpu=True,\n",
    "        seed=seed,\n",
    "        # if you changed eval to require model_uri/model_path, leave it unset here\n",
    "        # and let the coordinator populate it from the training result.\n",
    "        # model_path=None,\n",
    "        # model_uri=None,\n",
    "    ),\n",
    "    dataset_snapshot=None,  # or pass a DatasetSnapshotResult if you want reproducibility\n",
    ")\n",
    "\n",
    "# Sample 5: {Model: MiniLM-L12-H384-uncased - Dataset: Glue}\n",
    "seed = random.randint(0, 10000)\n",
    "config_5 = CoordinatorWorkflowConfig(\n",
    "    fine_tune_config=BertFineTuneConfig(\n",
    "        model_name=\"microsoft/MiniLM-L12-H384-uncased\",\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=\"sst2\",\n",
    "        num_epochs=2,\n",
    "        batch_size=4,  # still MPS-safe\n",
    "        learning_rate=3e-5,  # MiniLM often prefers slightly lower LR\n",
    "        max_seq_length=64,  # safe starting point\n",
    "        use_gpu=True,\n",
    "        max_train_samples=2_000,\n",
    "        max_eval_samples=1_000,\n",
    "        shuffle_before_select=True,\n",
    "        seed=seed,\n",
    "        # Optional schema overrides (usually not needed for GLUE)\n",
    "        # text_field=None,\n",
    "        # text_pair_field=None,\n",
    "        # label_field=None,\n",
    "        # task_type=\"auto\",\n",
    "    ),\n",
    "    evaluation_config=BertEvalRequest(\n",
    "        # run_id filled in by coordinator\n",
    "        run_id=None,\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=\"sst2\",\n",
    "        split=\"validation\",\n",
    "        max_eval_samples=1_000,\n",
    "        max_seq_length=64,\n",
    "        batch_size=32,\n",
    "        use_gpu=True,\n",
    "        seed=seed,\n",
    "        # If your eval requires an explicit model path/URI,\n",
    "        # leave it unset here and let the coordinator fill it.\n",
    "        # model_path=None,\n",
    "        # model_uri=None,\n",
    "    ),\n",
    "    dataset_snapshot=None,  # pass a snapshot if you want strict reproducibility\n",
    ")\n",
    "# Sample 6: {Model: DeBERTa-v3-small - Dataset: Glue}\n",
    "seed = random.randint(0, 10000)\n",
    "config_6 = CoordinatorWorkflowConfig(\n",
    "    fine_tune_config=BertFineTuneConfig(\n",
    "        model_name=\"microsoft/deberta-v3-small\",\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=\"sst2\",\n",
    "        num_epochs=2,\n",
    "        batch_size=2,  # DeBERTa tends to be heavier on memory (safer on MPS)\n",
    "        learning_rate=2e-5,  # common stable starting LR for DeBERTa fine-tuning\n",
    "        max_seq_length=64,  # start safe; bump to 96/128 once stable\n",
    "        use_gpu=True,\n",
    "        max_train_samples=2_000,\n",
    "        max_eval_samples=1_000,\n",
    "        shuffle_before_select=True,\n",
    "        seed=seed,\n",
    "        # Optional schema overrides (usually not needed for GLUE)\n",
    "        # text_field=None,\n",
    "        # text_pair_field=None,\n",
    "        # label_field=None,\n",
    "        # task_type=\"auto\",\n",
    "    ),\n",
    "    evaluation_config=BertEvalRequest(\n",
    "        run_id=None,  # coordinator fills this in\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=\"sst2\",\n",
    "        split=\"validation\",\n",
    "        max_eval_samples=1_000,\n",
    "        max_seq_length=64,\n",
    "        batch_size=32,\n",
    "        use_gpu=True,\n",
    "        seed=seed,\n",
    "        # model_path/model_uri left for coordinator to populate from training result\n",
    "    ),\n",
    "    dataset_snapshot=None,\n",
    ")\n",
    "# Sample 7: {Model: SciBERT - Dataset: SciCite}\n",
    "config_7 = CoordinatorWorkflowConfig(\n",
    "    fine_tune_config=BertFineTuneConfig(\n",
    "        model_name=\"allenai/scibert_scivocab_uncased\",\n",
    "        dataset_name=\"scicite\",  # start with SST-2 to validate pipeline\n",
    "        dataset_config_name=\"default\",\n",
    "        use_gpu=True,\n",
    "        max_train_samples=2_000,\n",
    "        max_eval_samples=1_000,\n",
    "        shuffle_before_select=True,\n",
    "    ),\n",
    "    evaluation_config=BertEvalRequest(\n",
    "        run_id=None,  # coordinator fills this in\n",
    "        dataset_name=\"scicite\",\n",
    "        dataset_config_name=\"default\",\n",
    "        split=\"validation\",\n",
    "        max_eval_samples=1_000,\n",
    "        use_gpu=True,\n",
    "    ),\n",
    "    dataset_snapshot=None,  # add snapshot later for reproducibility\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Ladder Sample Configurations\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Give this sweep a unique experiment identifier so that all per-stage run IDs\n",
    "# can be grouped together in logs and under ``./bert_runs``.\n",
    "ladder_id = uuid.uuid4()  # Replace with custom naming logic as desired.\n",
    "\n",
    "# Sample 1: HPO Scaling Ladder\n",
    "ladder_config_1 = SweepRequest(\n",
    "    experiment_id=f\"Bert-ladder-sweep-{ladder_id}\",\n",
    "    base=config_6,\n",
    "    space=SweepSpace(\n",
    "        learning_rate=(5e-5, 1e-5),\n",
    "        batch_size=[\n",
    "            2,\n",
    "            32,\n",
    "        ],  # TODO: Increase batch size in each rung of the ladder, instead of using the ladder to select batch size. Currently, the approach heavily biases towards small batch sizes.\n",
    "        num_epochs=[2, 8],\n",
    "        max_seq_length=[64, 256],\n",
    "    ),\n",
    "    num_trials=12,  # increase this for actual research, but ensure the machine has enough compute and memory or move to an autoscaling cluster\n",
    "    max_concurrency=4,\n",
    "    seed=random.randint(0, 10000),\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Starter Main Function\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    # 1. Connect to Temporal Server using the Pydantic data converter so our\n",
    "    # request/response models can be passed directly as workflow arguments.\n",
    "    client = await Client.connect(\"localhost:7233\", data_converter=pydantic_data_converter)\n",
    "\n",
    "    # 2. Pick the request to run. For the tutorial this is a single ladder\n",
    "    # sweep, but you can easily swap in a different ``SweepRequest`` here.\n",
    "    request = ladder_config_1\n",
    "\n",
    "    # 3. Start the workflow and wait for the result. We call the ``run`` method\n",
    "    # on the workflow class directly; Temporal will assign a fresh workflow\n",
    "    # execution to the ID provided below.\n",
    "    result = await client.execute_workflow(\n",
    "        LadderSweepWorkflow.run,\n",
    "        request,\n",
    "        id=f\"bert-ladder-{ladder_id}\",\n",
    "        task_queue=\"bert-eval-task-queue\",\n",
    "    )\n",
    "\n",
    "    # 4. Print a concise, tabular summary of the winning candidate & result.\n",
    "    results = result if isinstance(result, (list, tuple)) else [result]\n",
    "\n",
    "    print(\"\\n=== BERT evaluation summary ===\")\n",
    "    header = f\"{'run_id':<36} {'dataset':<20} {'split':<10} {'examples':>10} {'accuracy':>9}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    for item in results:\n",
    "        dataset = f\"{item.dataset_name}/{item.dataset_config_name}\"\n",
    "        print(\n",
    "            f\"{item.run_id:<36} \"\n",
    "            f\"{dataset:<20} \"\n",
    "            f\"{item.split:<10} \"\n",
    "            f\"{item.num_examples:>10} \"\n",
    "            f\"{item.accuracy:>9.3f}\",\n",
    "        )\n",
    "\n",
    "    # If the ladder workflow annotated the best result with ablation metadata,\n",
    "    # print the improvement in accuracy over the ablation baseline.\n",
    "    best = results[0]\n",
    "    baseline = getattr(best, \"baseline_accuracy\", None)\n",
    "    improvement = getattr(best, \"improvement_vs_baseline\", None)\n",
    "    if baseline is not None and improvement is not None:\n",
    "        print(\n",
    "            \"\\nBest run \"\n",
    "            f\"{best.run_id} improved accuracy by {improvement:.3f} \"\n",
    "            f\"over the ablation baseline \"\n",
    "            f\"(baseline={baseline:.3f}, best={best.accuracy:.3f}).\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246cfce-7fba-4e9c-8ce2-544f1e7ffce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Training_Demo)",
   "language": "python",
   "name": "training_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
